/**
 * @file sr-deploy-contracts.ts
 *
 * Handles the deterministic deployment of smart contracts across multiple chains
 * and environments with version-derived salts.
 * 
 * This is a critical part of the semantic release process for cross-chain protocols,
 * ensuring contracts deploy to the same addresses across all networks. The deployment
 * uses CREATE2/CREATE3 with carefully computed salts based on the semantic version number.
 *
 * Key features:
 * - Salt generation from semantic version for deterministic addresses
 * - Multi-environment support (production and pre-production)
 * - Parallel deployment to multiple chains with environment-specific salts
 * - Consolidated tracking of deployment results across all chains and environments
 * - JSON output generation for client library consumption
 * - CSV generation for contract verification tools
 */
import path from 'path'
import fs from 'fs'
import { parse as parseCSV } from 'csv-parse/sync'
import { determineSalts } from '../utils/extract-salt'
import { getAddress, Hex } from 'viem'
import { SemanticContext } from './sr-prepare'
import {
  PATHS,
  ENV_VARS,
  getDeploymentResultsPath,
  getDeployedAddressesJsonPath,
  getBuildDirPath,
} from './constants'
import dotenv from 'dotenv'
import { Logger } from './helpers'
import { validateEnvVariables } from '../utils/envUtils'
import { executeProcess } from '../utils/processUtils'
import { generateDeploymentFile } from './gen-bytecode'

dotenv.config()

interface Contract {
  address: string
  name: string
  chainId: number
  environment?: string
  contractPath?: string
}

// Define the type for CSV parser records
interface DeploymentRecord {
  ChainID: string
  ContractAddress: string
  ContractPath: string
  ContractArguments: string
}

interface DeploymentResult {
  contracts: Contract[]
  success: boolean
}

/**
 * Deploys Eco Routes contracts to multiple chains with deterministic addressing.
 *
 * @param context - The semantic release context containing version info and logger
 * @param packageName - The name of the package being released
 * @returns Promise that resolves when all deployments are complete
 * @throws Error if deployment fails on any chain
 */
export async function deployRoutesContracts(
  context: SemanticContext,
  packageName: string,
): Promise<void> {
  const { nextRelease, logger, cwd } = context
  try {
    // Clean up existing build directory if it exists
    const buildDir = getBuildDirPath(cwd)
    if (fs.existsSync(buildDir)) {
      logger.log(`Deleting existing build directory: ${buildDir}`)
      fs.rmSync(buildDir, { recursive: true, force: true })
      logger.log('Build directory deleted successfully')
    }

    // Create build directory
    fs.mkdirSync(buildDir, { recursive: true })
    logger.log(`Created build directory: ${buildDir}`)

    // Determine salts based on version
    const { rootSalt, preprodRootSalt } = await determineSalts(
      nextRelease!.version,
      logger,
    )
    //Deploy the contracts using the generated bytecode
    logger.log('Deploying contracts...')
    const {contracts, success} = await deployContracts([
      { value: rootSalt, environment: 'default' },
      { value: preprodRootSalt, environment: 'pre' },
    ], logger, cwd)
    if(!success) {
      throw new Error('Deployment failed')
    }

    // Deploy the generated deploymentAddresses
    await generateDeploymentAddressesJSON(contracts, context)
  } catch (error) {
    logger.error('❌ Contract deployment failed')
    logger.error((error as Error).message)
    throw error
  }
}

/**
 * Generates the deployAddresses.json file from contract deployment results.
 * This file is a critical artifact that maps chain IDs to contract addresses and
 * is included in the published package for client consumption.
 * 
 * The function processes raw deployment data into a structured JSON format,
 * grouping contracts by chain ID and environment, and formatting addresses
 * according to EIP-55 checksum standards.
 *
 * @param contracts - Array of deployed contract objects with chain ID, name, and address
 * @param context - Semantic release context with logger and working directory
 * @returns Promise that resolves when JSON file is successfully written
 * @throws Error if JSON generation or file writing fails
 */
async function generateDeploymentAddressesJSON(contracts: Contract[], context: SemanticContext): Promise<void> {
  const { nextRelease, logger, cwd } = context
  logger.log('Creating the deployAddresses.json...')

  try {

    const contractsJson = processContractsForJson(contracts)

    // Save to deployed addresses JSON
    const deployedAddressesPath = getDeployedAddressesJsonPath(cwd)
    fs.writeFileSync(
      deployedAddressesPath,
      JSON.stringify(contractsJson, null, 2)
    )

    logger.log(`Contract addresses saved to ${deployedAddressesPath}`)
    logger.log('✅ Contract deployment completed successfully')
  } catch (error) {
    logger.error(`Deployment process failed: ${(error as Error).message}`)
    throw error
  }
}

/**
 * Processes contract deployment data into a structured JSON format for client consumption.
 * This function transforms the raw contract deployment records into a nested structure
 * that organizes contracts by chain ID and environment, making them easily accessible
 * by client applications.
 * 
 * The output format follows the pattern:
 * {
 *   "chainId": {                   // Chain ID or "chainId-environment" for non-default environments
 *     "ContractName": "0xAddress", // EIP-55 checksum address
 *     ...
 *   },
 *   ...
 * }
 *
 * @param contracts - Array of deployed Contract objects with chain ID, environment, name, and address
 * @returns A nested record mapping chain IDs to contract name/address pairs
 */
function processContractsForJson(
  contracts: Contract[],
): Record<string, Record<string, string>> {
  // Group by chain ID and environment
  const groupedContracts: Record<string, Contract[]> = {}

  for (const contract of contracts) {
    const key = `${contract.chainId}${contract.environment === 'default' ? '' : `-${contract.environment}`}`
    if (!groupedContracts[key]) {
      groupedContracts[key] = []
    }
    groupedContracts[key].push(contract)
  }

  // Convert to desired format
  return Object.fromEntries(
    Object.entries(groupedContracts).map(([key, contracts]) => {
      const names = contracts.map((c) => c.name)
      const addresses = contracts.map((c) => c.address)

      const contractMap: Record<string, string> = {}
      for (let i = 0; i < names.length; i++) {
        // Only add addresses that exist and are not empty strings
        if (addresses[i] && addresses[i].trim() !== '') {
          contractMap[names[i]] = getAddress(addresses[i])
        }
      }

      return [key, contractMap]
    }),
  )
}

/**
 * Deploys contracts using specific salts for each environment.
 * This function handles the execution of the deployRoutes.sh script with
 * appropriate environment variables, ensuring the SALT value is correctly
 * passed to the bash script for deterministic deployment.
 * 
 * The function deploys to multiple environments in sequence, each with its own salt,
 * and collects all deployment results into a consolidated record. It also generates
 * a combined deployment results file for verification purposes.
 *
 * @param salts - Array of salt objects containing the hex value and environment name
 * @param logger - Logger instance for output messages
 * @param cwd - Current working directory
 * @returns Promise resolving to the deployment result with contracts array and success status
 * @throws Error if deployment process fails for any reason
 */
async function deployContracts(
  salts: { value: Hex; environment: string }[],
  logger: Logger,
  cwd: string,) {
  // Check for required environment variables
  validateEnvVariables()

  try {
    let contracts: Contract[] = []
    // Remove previous results sum file
    const allDeployPath = path.join(PATHS.OUTPUT_DIR, PATHS.DEPLOYMENT_ALL_FILE)
    if (fs.existsSync(allDeployPath)) {
      logger.log(`Cleaning up previous deployment results file: ${allDeployPath}`)
      fs.unlinkSync(allDeployPath)
    }
    for (const { value: salt, environment } of salts) {
      // Run the deployment script
      // Create a properly merged environment by spreading process.env first
      const exitCode = await executeProcess(PATHS.DEPLOY_SCRIPT, [],{
        ...process.env,  // Spread existing env first
        [ENV_VARS.SALT]: salt,  // Then override with our custom value
      }, cwd)
      logger.log(`Deployment process exited with code ${exitCode}`)
      contracts = [...contracts, ...parseDeploymentResults(getDeploymentResultsPath(cwd), environment, logger)] 
    }
    
    return { contracts, success: true }
  } catch (error) {
    logger.error(`Deployment process failed: ${(error as Error).message}`)
    return { contracts: [], success: false }
  }
}

/**
 * Parses deployment results from the CSV-formatted results file and processes them into
 * structured contract objects with standardized metadata. Handles aggregating results
 * across multiple deployments and maintaining a comprehensive record of all deployments.
 *
 * @param filePath - Path to the CSV file containing deployment results
 * @param deployEnv - Environment name (e.g., 'default', 'pre') for categorizing results
 * @param logger - Optional logger instance for output messages and debugging
 * @returns Array of Contract objects parsed from the file with full metadata
 * 
 * @example
 * // CSV format: ChainID,Environment,ContractName,ContractAddress,ContractPath
 * // Parse deployment results for the 'pre' environment
 * const contracts = parseDeploymentResults('results.csv', 'pre', logger);
 */
function parseDeploymentResults(filePath: string, deployEnv: string, logger?: Logger): Contract[] {
  if (!fs.existsSync(filePath)) {
    logger?.log(`Deployment results file not found: ${filePath}`)
    return []
  }

  try {
    const fileContent = fs.readFileSync(filePath, 'utf-8')

    // Skip empty file
    if (!fileContent.trim()) {
      logger?.log(`Deployment results file is empty: ${filePath}`)
      return []
    }

    // CSV parse options
    const parseOptions = {
      columns: true, // Use first row as column names
      skip_empty_lines: true,
      trim: true,
      delimiter: ',', // Specify delimiter explicitly
      comment: '#', // Handle any comment lines in the file
    }

    // Parse CSV content
    const records = parseCSV(fileContent, parseOptions) as DeploymentRecord[]
    // Define the path for the fullDeploy.csv file
    const fullDeployPath = path.join(PATHS.OUTPUT_DIR, PATHS.DEPLOYMENT_ALL_FILE)

    // Check if the file exists
    const fileExists = fs.existsSync(fullDeployPath)

    // Append or create the file
    if (fileExists) {
      logger?.log(`Appending deployment results to existing file: ${fullDeployPath}`)
      // Remove the header line from the appended content if the file already exists
      const lines = fileContent.split('\n')
      if (lines.length > 0 && lines[0].startsWith('ChainID')) {
        lines.shift() // Remove the header line
      }
      fs.appendFileSync(fullDeployPath, lines.join('\n'))
    } else {
      logger?.log(`Creating new deployment results file: ${fullDeployPath}`)
      fs.writeFileSync(fullDeployPath, fileContent)
    }
    const contracts: Contract[] = []

    // Process each record in the new format
    for (const record of records) {
      const chainId = parseInt(record.ChainID, 10)
      const environment = deployEnv || 'default'
      const contractAddress = record.ContractAddress
      const contractPath = record.ContractPath

      // Skip undefined or empty addresses
      if (!contractAddress || contractAddress === 'undefined' || contractAddress.trim() === '') {
        logger?.log(`Skipping undefined address for contract ${contractPath} on chain ${chainId}`)
        continue
      }

      contracts.push({
        name: contractPath.split(':')[1], // Extract contract name from path
        address: contractAddress,
        chainId,
        environment,
        contractPath
      })
    }

    logger?.log(`Parsed ${contracts.length} contract addresses from deployment results`)
    return contracts
  } catch (error) {
    // Log error but don't crash the process
    if (logger) {
      logger.error(
        `Error parsing deployment results from ${filePath}: ${(error as Error).message}`,
      )
    } else {
      console.error(
        `Error parsing deployment results: ${(error as Error).message}`,
      )
    }
    return []
  }
}

/**
 * Creates verification mapping file with actual contract addresses after deployment
 * This simple file just maps chain IDs and contract names to actual addresses
 * The verification script will read this and the bytecode file to get all needed data
 * Format: ChainID,Environment,ContractName,ContractAddress,ContractPath
 * @param cwd Current working directory 
 * @param contracts Array of deployed contract objects
 * @param logger Logger instance
 */
function updateVerificationFile(cwd: string, contracts: Contract[], logger?: Logger): void {
  try {
    const outputDir = path.join(cwd, PATHS.OUTPUT_DIR)
    const verifyFilePath = path.join(outputDir, 'verify-data.txt')
    const bytecodePath = path.join(cwd, 'build', PATHS.DEPLOYMENT_BYTECODE_FILE)

    // Ensure output directory exists
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true })
      logger?.log(`Created output directory: ${outputDir}`)
    }

    // Create a new verification file with actual addresses
    logger?.log(`Creating verification data file at ${verifyFilePath}`)

    // Check if bytecode file exists
    if (!fs.existsSync(bytecodePath)) {
      logger?.error(`Bytecode file not found at ${bytecodePath}`)
      return
    }

    // Generate verification lines based on deployed contracts
    const verificationLines: string[] = []

    // Group contracts by environment, chain ID, and contract name for easier lookup
    // This ensures we preserve all environments and don't overwrite any
    const contractsByEnvChainName = new Map<string, Map<string, Map<string, Contract>>>()

    for (const contract of contracts) {
      const environment = contract.environment || 'default'
      const chainId = contract.chainId.toString()
      const contractName = contract.name

      // Create nested maps as needed
      if (!contractsByEnvChainName.has(environment)) {
        contractsByEnvChainName.set(environment, new Map<string, Map<string, Contract>>())
      }

      const envMap = contractsByEnvChainName.get(environment)!

      if (!envMap.has(chainId)) {
        envMap.set(chainId, new Map<string, Contract>())
      }

      const chainMap = envMap.get(chainId)!
      chainMap.set(contractName, contract)
    }

    // Create an array to collect all verification entries
    // Each entry is: { chainId, environment, contractName, contractAddress, contractPath }
    const verificationEntries: Array<{
      chainId: string
      environment: string
      contractName: string
      contractAddress: string
      contractPath: string
    }> = []

    // First, collect all entries - this preserves all environment/chain combinations
    for (const [environment, envMap] of contractsByEnvChainName.entries()) {
      for (const [chainId, contractsMap] of envMap.entries()) {
        for (const [contractName, contract] of contractsMap.entries()) {
          // Use contract path from the contract object if available, otherwise use default pattern
          const contractPath = contract.contractPath || `contracts/${contractName}.sol:${contractName}`

          // Add to verification entries
          verificationEntries.push({
            chainId,
            environment,
            contractName,
            contractAddress: contract.address,
            contractPath
          })

          logger?.log(`Prepared verification data for ${contractName} on chain ${chainId} in environment ${environment} with address ${contract.address}`)
        }
      }
    }

    // Sort entries to get a consistent output (by chainId then contractName)
    verificationEntries.sort((a, b) => {
      // First sort by chainId
      if (a.chainId !== b.chainId) {
        return parseInt(a.chainId) - parseInt(b.chainId)
      }
      // Then by environment
      if (a.environment !== b.environment) {
        return a.environment.localeCompare(b.environment)
      }
      // Then by contract name
      return a.contractName.localeCompare(b.contractName)
    })

    // Add header line
    verificationLines.push("ChainID,Environment,ContractName,ContractAddress,ContractPath")

    // Generate the verification lines - format matching the CSV
    // ChainID,Environment,ContractName,ContractAddress,ContractPath
    for (const entry of verificationEntries) {
      verificationLines.push(`${entry.chainId},${entry.environment},${entry.contractName},${entry.contractAddress},${entry.contractPath}`)
    }

    logger?.log(`Generated ${verificationLines.length - 1} verification entries sorted by chain ID and contract name`)

    // Write verification data to file
    fs.writeFileSync(verifyFilePath, verificationLines.join('\n'))

    // Log the results, showing first few entries for verification
    logger?.log(`Verification data created at ${verifyFilePath} with ${verificationLines.length - 1} entries`)

    // Debug log the first few entries (up to 3)
    const samplesToShow = Math.min(3, verificationLines.length - 1)
    if (samplesToShow > 0) {
      logger?.log(`First ${samplesToShow} verification entries (of ${verificationLines.length - 1} total):`)
      for (let i = 1; i <= samplesToShow; i++) { // Start at 1 to skip header
        const parts = verificationLines[i].split(',')
        logger?.log(`  - Chain ${parts[0]}, Environment ${parts[1]}, Contract ${parts[2]}, Address ${parts[3]}`)
      }
    }

  } catch (error) {
    logger?.error(`Failed to create verification file: ${(error as Error).message}`)
  }
}