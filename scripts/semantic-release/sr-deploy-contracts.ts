/**
 * @file sr-deploy-contracts.ts
 *
 * Handles the deterministic deployment of smart contracts across multiple chains
 * and environments with version-derived salts.
 *
 * This is a critical part of the semantic release process for cross-chain protocols,
 * ensuring contracts deploy to the same addresses across all networks. The deployment
 * uses CREATE2/CREATE3 with carefully computed salts based on the semantic version number.
 *
 * Key features:
 * - Salt generation from semantic version for deterministic addresses
 * - Multi-environment support (production and pre-production)
 * - Parallel deployment to multiple chains with environment-specific salts
 * - Consolidated tracking of deployment results across all chains and environments
 * - JSON output generation for client library consumption
 * - CSV generation for contract verification tools
 */
import path from 'path'
import fs from 'fs'
// eslint-disable-next-line node/no-missing-import
import { parse as parseCSV } from 'csv-parse/sync'
import { determineSalts, getBaseVersion } from '../utils/extract-salt'
import { getAddress, Hex, hexToBytes, keccak256, toHex } from 'viem'
import { SemanticContext } from './sr-prepare'
import {
  PATHS,
  CHAIN_IDS,
  getDeploymentResultsPath,
  getDeployedAddressesJsonPath,
  getBuildDirPath,
  ENV_VARS,
} from './constants'
import dotenv from 'dotenv'
import { Logger } from './helpers'
import { validateEnvVariables } from '../utils/envUtils'
import { executeProcess } from '../utils/processUtils'
import { getDeployerAddress } from '../utils/address'
import { create2470Create3Address, createCreateXSalt, createXCreate3Address } from '../contracts'

dotenv.config()

interface CrossChainProverData {
  tron: {
    production: {
      portal: string
      polymerProver: string
    }
    staging: {
      portal: string
      polymerProver: string
    }
  }
  solana: {
    production: {
      portal: string
      hyperProver: string
    }
    staging: {
      portal: string
      hyperProver: string
    }
  }
}

interface Contract {
  address: string
  name: string
  chainId: number
  environment?: string
  contractPath?: string
}

// Define the type for CSV parser records
interface DeploymentRecord {
  ChainID: string
  ContractAddress: string
  ContractPath: string
  ContractArguments: string
}

/**
 * Deploys Eco Routes contracts to multiple chains with deterministic addressing.
 *
 * @param context - The semantic release context containing version info and logger
 * @param packageName - The name of the package being released
 * @returns Promise that resolves when all deployments are complete
 * @throws Error if deployment fails on any chain
 */
export async function deployRoutesContracts(
  context: SemanticContext,
  packageName: string,
): Promise<void> {
  const { nextRelease, logger, cwd } = context
  try {
    // Clean up existing build directory if it exists
    const buildDir = getBuildDirPath(cwd)
    if (fs.existsSync(buildDir)) {
      logger.log(`Deleting existing build directory: ${buildDir}`)
      fs.rmSync(buildDir, { recursive: true, force: true })
      logger.log('Build directory deleted successfully')
    }

    // Create build directory
    fs.mkdirSync(buildDir, { recursive: true })
    logger.log(`Created build directory: ${buildDir}`)

    // Determine salts based on version
    const { rootSalt, stagingRootSalt } = await determineSalts(
      nextRelease!.version,
      logger,
    )
    // Deploy the contracts using the generated bytecode
    logger.log('Deploying contracts...')
    const { contracts, success } = await deployContracts(
      [
        { value: rootSalt, environment: 'production' },
        { value: stagingRootSalt, environment: 'staging' },
      ],
      nextRelease!.version,
      logger,
      cwd,
    )
    if (!success) {
      throw new Error('Deployment failed')
    }

    // Deploy the generated deploymentAddresses
    await generateDeploymentAddressesJSON(
      contracts,
      nextRelease!.version,
      context,
    )
  } catch (error) {
    logger.error('❌ Contract deployment failed')
    logger.error((error as Error).message)
    throw error
  }
}

/**
 * Generates the deployAddresses.json file from contract deployment results.
 * This file is a critical artifact that maps chain IDs to contract addresses and
 * is included in the published package for client consumption.
 *
 * The function processes raw deployment data into a structured JSON format,
 * grouping contracts by chain ID and environment, and formatting addresses
 * according to EIP-55 checksum standards.
 *
 * @param contracts - Array of deployed contract objects with chain ID, name, and address
 * @param context - Semantic release context with logger and working directory
 * @returns Promise that resolves when JSON file is successfully written
 * @throws Error if JSON generation or file writing fails
 */
async function generateDeploymentAddressesJSON(
  contracts: Contract[],
  version: string,
  context: SemanticContext,
): Promise<void> {
  const { logger, cwd } = context
  logger.log('Creating the deployAddresses.json...')

  try {
    const contractsJson = processContractsForJson(contracts, version, context)

    // Save to deployed addresses JSON
    const deployedAddressesPath = getDeployedAddressesJsonPath(cwd)
    fs.writeFileSync(
      deployedAddressesPath,
      JSON.stringify(contractsJson, null, 2),
    )

    logger.log(`Contract addresses saved to ${deployedAddressesPath}`)
    logger.log('✅ Contract deployment completed successfully')
  } catch (error) {
    logger.error(`Deployment process failed: ${(error as Error).message}`)
    throw error
  }
}

/**
 * Adds cross-chain addresses from deploy files to the grouped contracts structure.
 * This function reads the version-specific deploy JSON file and adds Tron and Solana
 * addresses to the contract groupings for both production and staging environments.
 *
 * @param groupedContracts - Existing grouped contracts structure to modify
 * @param cwd - Current working directory to locate deploy files
 * @param version - Semantic version string to determine config file name
 * @param logger - Logger instance for output messages
 */
function addCrossChainAddresses(
  groupedContracts: Record<string, Contract[]>,
  cwd: string,
  version: string,
  logger: Logger,
): void {
  try {
    // Get the full cross-chain data
    const baseVersion = getBaseVersion(version, logger)
    const configFileName = `${baseVersion.replace('.', '_')}_x-mainnet.json`
    const configPath = path.join(cwd, 'deploys', configFileName)

    if (!fs.existsSync(configPath)) {
      logger.log(`Cross-chain config file not found: ${configPath}`)
      return
    }

    const configData: CrossChainProverData = JSON.parse(
      fs.readFileSync(configPath, 'utf-8'),
    )

    // Add Tron addresses for production environment
    if (
      configData.tron?.production?.portal &&
      configData.tron?.production?.polymerProver
    ) {
      const tronProdKey = `${CHAIN_IDS.TRON_MAINNET}`
      if (!groupedContracts[tronProdKey]) {
        groupedContracts[tronProdKey] = []
      }
      groupedContracts[tronProdKey].push(
        {
          name: 'Portal',
          address: configData.tron.production.portal,
          chainId: CHAIN_IDS.TRON_MAINNET,
          environment: 'production',
        },
        {
          name: 'PolymerProver',
          address: configData.tron.production.polymerProver,
          chainId: CHAIN_IDS.TRON_MAINNET,
          environment: 'production',
        },
      )
    }

    // Add Tron addresses for staging environment
    if (
      configData.tron?.staging?.portal &&
      configData.tron?.staging?.polymerProver
    ) {
      const tronStagingKey = `${CHAIN_IDS.TRON_MAINNET}-staging`
      if (!groupedContracts[tronStagingKey]) {
        groupedContracts[tronStagingKey] = []
      }
      groupedContracts[tronStagingKey].push(
        {
          name: 'Portal',
          address: configData.tron.staging.portal,
          chainId: CHAIN_IDS.TRON_MAINNET,
          environment: 'staging',
        },
        {
          name: 'PolymerProver',
          address: configData.tron.staging.polymerProver,
          chainId: CHAIN_IDS.TRON_MAINNET,
          environment: 'staging',
        },
      )
    }

    // Add Solana addresses for production environment
    if (
      configData.solana?.production?.portal &&
      configData.solana?.production?.hyperProver
    ) {
      const solanaProdKey = `${CHAIN_IDS.SOLANA_MAINNET}`
      if (!groupedContracts[solanaProdKey]) {
        groupedContracts[solanaProdKey] = []
      }
      groupedContracts[solanaProdKey].push(
        {
          name: 'Portal',
          address: configData.solana.production.portal,
          chainId: CHAIN_IDS.SOLANA_MAINNET,
          environment: 'production',
        },
        {
          name: 'HyperProver',
          address: configData.solana.production.hyperProver,
          chainId: CHAIN_IDS.SOLANA_MAINNET,
          environment: 'production',
        },
      )
    }

    // Add Solana addresses for staging environment
    if (
      configData.solana?.staging?.portal &&
      configData.solana?.staging?.hyperProver
    ) {
      const solanaStagingKey = `${CHAIN_IDS.SOLANA_MAINNET}-staging`
      if (!groupedContracts[solanaStagingKey]) {
        groupedContracts[solanaStagingKey] = []
      }
      groupedContracts[solanaStagingKey].push(
        {
          name: 'Portal',
          address: configData.solana.staging.portal,
          chainId: CHAIN_IDS.SOLANA_MAINNET,
          environment: 'staging',
        },
        {
          name: 'HyperProver',
          address: configData.solana.staging.hyperProver,
          chainId: CHAIN_IDS.SOLANA_MAINNET,
          environment: 'staging',
        },
      )
    }

    logger.log(
      `Added cross-chain addresses for Tron (${CHAIN_IDS.TRON_MAINNET}) and Solana (${CHAIN_IDS.SOLANA_MAINNET})`,
    )
  } catch (error) {
    logger.error(
      `Error adding cross-chain addresses: ${(error as Error).message}`,
    )
  }
}

/**
 * Processes contract deployment data into a structured JSON format for client consumption.
 * This function transforms the raw contract deployment records into a nested structure
 * that organizes contracts by chain ID and environment, making them easily accessible
 * by client applications.
 *
 * The output format follows the pattern:
 * {
 *   "chainId": {                   // Chain ID or "chainId-environment" for non-default environments
 *     "ContractName": "0xAddress", // EIP-55 checksum address
 *     ...
 *   },
 *   ...
 * }
 *
 * @param contracts - Array of deployed Contract objects with chain ID, environment, name, and address
 * @returns A nested record mapping chain IDs to contract name/address pairs
 */
function processContractsForJson(
  contracts: Contract[],
  version: string,
  context: SemanticContext,
): Record<string, Record<string, string>> {
  const { logger, cwd } = context

  // Group by chain ID and environment
  const groupedContracts: Record<string, Contract[]> = {}

  for (const contract of contracts) {
    const key = `${contract.chainId}${contract.environment === 'production' ? '' : `-${contract.environment}`}`
    if (!groupedContracts[key]) {
      groupedContracts[key] = []
    }
    groupedContracts[key].push(contract)
  }

  // Add cross-chain addresses from deploy files
  addCrossChainAddresses(groupedContracts, cwd, version, logger)

  // Convert to desired format
  return Object.fromEntries(
    Object.entries(groupedContracts).map(([key, contracts]) => {
      const names = contracts.map((c) => c.name)
      const addresses = contracts.map((c) => c.address)

      const contractMap: Record<string, string> = {}
      for (let i = 0; i < names.length; i++) {
        // Only add addresses that exist and are not empty strings
        if (addresses[i] && addresses[i].trim() !== '') {
          // Check if this is a cross-chain address (32 bytes) or standard EVM address (20 bytes)
          const address = addresses[i]
          const isCrossChainAddress =
            address.length === 66 && address.startsWith('0x') // 32 bytes = 64 hex chars + 0x prefix

          // Apply EIP-55 checksum only to standard EVM addresses
          contractMap[names[i]] = isCrossChainAddress
            ? address
            : getAddress(address)
        }
      }

      return [key, contractMap]
    }),
  )
}

/**
 * Deploys contracts using specific salts for each environment.
 * This function handles the execution of the deployRoutes.sh script with
 * appropriate environment variables, ensuring the SALT value is correctly
 * passed to the bash script for deterministic deployment.
 *
 * The function deploys to multiple environments in sequence, each with its own salt,
 * and collects all deployment results into a consolidated record. It also generates
 * a combined deployment results file for verification purposes.
 *
 * @param salts - Array of salt objects containing the hex value and environment name
 * @param version - Semantic version string to determine cross-chain config file
 * @param logger - Logger instance for output messages
 * @param cwd - Current working directory
 * @returns Promise resolving to the deployment result with contracts array and success status
 * @throws Error if deployment process fails for any reason
 */
async function deployContracts(
  salts: { value: Hex; environment: 'production' | 'staging' }[],
  version: string,
  logger: Logger,
  cwd: string,
) {
  // Check for required environment variables
  validateEnvVariables()

  try {
    let contracts: Contract[] = []
    // Remove previous results sum file
    const allDeployPath = path.join(PATHS.OUTPUT_DIR, PATHS.DEPLOYMENT_ALL_FILE)
    if (fs.existsSync(allDeployPath)) {
      logger.log(
        `Cleaning up previous deployment results file: ${allDeployPath}`,
      )
      fs.unlinkSync(allDeployPath)
    }
    for (const { value: salt, environment } of salts) {
      const resultsPath = getDeploymentResultsPath(cwd)
      if (fs.existsSync(resultsPath)) {
        logger.log(
          `Cleaning up previous deployment results file: ${resultsPath}`,
        )
        fs.unlinkSync(resultsPath)
      }

      // Generate HyperProver CreateX address using the salt and deployer
      // Use the new getHyperProverSalt function to match Solidity implementation
      const deployer = getDeployerAddress()

      // override for production provers getting redeployed
      let proverSaltSuffix = ''
      switch (environment) {
        case 'production':
          proverSaltSuffix = process.env.PROVER_SALT_SUFFIX_PROD || ''
          break
        case 'staging':
          proverSaltSuffix = process.env.PROVER_SALT_SUFFIX_STAGING || ''
          break
      }
      // Do secondary keccak256 force a redeploy for version 2.8.* for the hyper prover
      const hyperProverSalt = createCreateXSalt(
        deployer,
        0,
        hexToBytes(
          keccak256(toHex(salt + 'HyperProver' + proverSaltSuffix)),
        ) as Uint8Array,
      )
      const polymerProverSalt = createCreateXSalt(
        deployer,
        0,
        hexToBytes(
          keccak256(toHex(salt + 'PolymerProver' + proverSaltSuffix)),
        ) as Uint8Array,
      )

      const hyperProverCreateXAddress = await createXCreate3Address(
        deployer,
        hyperProverSalt,
      )

      const hyperProver2470Address = await create2470Create3Address(
        deployer,
        hyperProverSalt,
      )

      const polymerProverCreateXAddress = await createXCreate3Address(
        deployer,
        polymerProverSalt,
      )

      const polymerProver2470Address = await create2470Create3Address(
        deployer,
        polymerProverSalt,
      )

      logger.log(
        `Generated HyperProver CreateX address: ${hyperProverCreateXAddress}`,
      )
      logger.log(
        `Generated HyperProver erc2470 address: ${hyperProver2470Address}`,
      )
      logger.log(
        `Generated PolymerProver CreateX address: ${polymerProverCreateXAddress}`,
      )
      logger.log(
        `Generated PolymerProver erc2470 address: ${polymerProver2470Address}`,
      )

      const { hyperSolanaProvers, polymerTronProvers } =
        readCrossChainProverAddresses(cwd, version, environment, logger)

      // Run the deployment script
      // Create a properly merged environment by spreading process.env first
      const exitCode = await executeProcess(
        PATHS.DEPLOY_SCRIPT,
        [],
        {
          ...process.env, // Spread existing env first
          [ENV_VARS.SALT]: salt, // Then override with our custom value
          [ENV_VARS.HYPER_PROVER_SALT]: hyperProverSalt, // Then override with our custom value
          [ENV_VARS.POLYMER_PROVER_SALT]: polymerProverSalt, // Then override with our custom value
          [ENV_VARS.HYPERPROVER_CREATEX_ADDRESS]: hyperProverCreateXAddress,
          [ENV_VARS.HYPERPROVER_2470_ADDRESS]: hyperProver2470Address,
          [ENV_VARS.POLYMER_PROVER_CREATEX_ADDRESS]:
            polymerProverCreateXAddress,
          [ENV_VARS.POLYMER_PROVER_2470_ADDRESS]: polymerProver2470Address,
          [ENV_VARS.HYPER_SOLANA_PROVERS]: hyperSolanaProvers.join(','),
          [ENV_VARS.POLYMER_TRON_PROVERS]: polymerTronProvers.join(','),
        },
        cwd,
      )
      logger.log(`Deployment process exited with code ${exitCode}`)
      contracts = [
        ...contracts,
        ...parseDeploymentResults(
          getDeploymentResultsPath(cwd),
          environment,
          logger,
        ),
      ]
    }

    return { contracts, success: true }
  } catch (error) {
    logger.error(`Deployment process failed: ${(error as Error).message}`)
    return { contracts: [], success: false }
  }
}

/**
 * Reads cross-chain prover addresses from the deployment configuration file.
 * This function extracts Solana HyperProver and Tron PolymerProver addresses
 * from the version-specific mainnet configuration JSON to pass to the deployment script.
 *
 * @param cwd - Current working directory to locate the config file
 * @param version - Semantic version string to determine config file name
 * @param environment - Environment to read addresses for ('production' or 'staging')
 * @param logger - Logger instance for output messages
 * @returns Object containing arrays of prover addresses
 */
function readCrossChainProverAddresses(
  cwd: string,
  version: string,
  environment: 'production' | 'staging',
  logger: Logger,
): { hyperSolanaProvers: string[]; polymerTronProvers: string[] } {
  try {
    // Use the same base version pattern as salt generation
    const baseVersion = getBaseVersion(version, logger)
    const configFileName = `${baseVersion.replace('.', '_')}_x-mainnet.json`
    const configPath = path.join(cwd, 'deploys', configFileName)

    if (!fs.existsSync(configPath)) {
      logger.log(`Cross-chain config file not found: ${configPath}`)
      return { hyperSolanaProvers: [], polymerTronProvers: [] }
    }

    const configData: CrossChainProverData = JSON.parse(
      fs.readFileSync(configPath, 'utf-8'),
    )

    const hyperSolanaProvers: string[] = []
    const polymerTronProvers: string[] = []

    // Extract Solana HyperProver addresses
    if (configData.solana?.[environment]?.hyperProver) {
      const address = configData.solana[environment].hyperProver.trim()
      if (address && address !== '') {
        hyperSolanaProvers.push(address)
      }
    }

    // Extract Tron PolymerProver addresses
    if (configData.tron?.[environment]?.polymerProver) {
      const address = configData.tron[environment].polymerProver.trim()
      if (address && address !== '') {
        polymerTronProvers.push(address)
      }
    }

    logger.log(
      `Found ${hyperSolanaProvers.length} Solana HyperProver addresses`,
    )
    logger.log(
      `Found ${polymerTronProvers.length} Tron PolymerProver addresses`,
    )

    return { hyperSolanaProvers, polymerTronProvers }
  } catch (error) {
    logger.error(
      `Error reading cross-chain prover addresses: ${(error as Error).message}`,
    )
    return { hyperSolanaProvers: [], polymerTronProvers: [] }
  }
}

/**
 * Parses deployment results from the CSV-formatted results file and processes them into
 * structured contract objects with standardized metadata. Handles aggregating results
 * across multiple deployments and maintaining a comprehensive record of all deployments.
 *
 * @param filePath - Path to the CSV file containing deployment results
 * @param deployEnv - Environment name (e.g., 'default', 'pre') for categorizing results
 * @param logger - Optional logger instance for output messages and debugging
 * @returns Array of Contract objects parsed from the file with full metadata
 *
 * @example
 * // CSV format: ChainID,Environment,ContractName,ContractAddress,ContractPath
 * // Parse deployment results for the 'pre' environment
 * const contracts = parseDeploymentResults('results.csv', 'pre', logger);
 */
function parseDeploymentResults(
  filePath: string,
  deployEnv: string,
  logger?: Logger,
): Contract[] {
  if (!fs.existsSync(filePath)) {
    logger?.log(`Deployment results file not found: ${filePath}`)
    return []
  }

  try {
    const fileContent = fs.readFileSync(filePath, 'utf-8')

    // Skip empty file
    if (!fileContent.trim()) {
      logger?.log(`Deployment results file is empty: ${filePath}`)
      return []
    }

    // CSV parse options
    const parseOptions = {
      columns: true, // Use first row as column names
      skip_empty_lines: true,
      trim: true,
      delimiter: ',', // Specify delimiter explicitly
      comment: '#', // Handle any comment lines in the file
    }

    // Parse CSV content
    const records = parseCSV(
      fileContent,
      parseOptions,
    ) as unknown as DeploymentRecord[]
    // Define the path for the fullDeploy.csv file
    const fullDeployPath = path.join(
      PATHS.OUTPUT_DIR,
      PATHS.DEPLOYMENT_ALL_FILE,
    )

    // Check if the file exists
    const fileExists = fs.existsSync(fullDeployPath)

    // Append or create the file
    if (fileExists) {
      logger?.log(
        `Appending deployment results to existing file: ${fullDeployPath}`,
      )
      // Remove the header line from the appended content if the file already exists
      const lines = fileContent.split('\n')
      if (lines.length > 0 && lines[0].startsWith('ChainID')) {
        lines.shift() // Remove the header line
      }
      fs.appendFileSync(fullDeployPath, lines.join('\n'))
    } else {
      logger?.log(`Creating new deployment results file: ${fullDeployPath}`)
      fs.writeFileSync(fullDeployPath, fileContent)
    }
    const contracts: Contract[] = []

    // Process each record in the new format
    for (const record of records) {
      const chainId = parseInt(record.ChainID, 10)
      const environment = deployEnv || 'default'
      const contractAddress = record.ContractAddress
      const contractPath = record.ContractPath

      // Skip undefined or empty addresses
      if (
        !contractAddress ||
        contractAddress === 'undefined' ||
        contractAddress.trim() === ''
      ) {
        logger?.log(
          `Skipping undefined address for contract ${contractPath} on chain ${chainId}`,
        )
        continue
      }

      contracts.push({
        name: contractPath.split(':')[1], // Extract contract name from path
        address: contractAddress,
        chainId,
        environment,
        contractPath,
      })
    }

    logger?.log(
      `Parsed ${contracts.length} contract addresses from deployment results`,
    )
    return contracts
  } catch (error) {
    // Log error but don't crash the process
    if (logger) {
      logger.error(
        `Error parsing deployment results from ${filePath}: ${(error as Error).message}`,
      )
    } else {
      console.error(
        `Error parsing deployment results: ${(error as Error).message}`,
      )
    }
    return []
  }
}
